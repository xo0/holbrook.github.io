
机器学习问题，通常可以分为三个步骤:

1. 数据准备与预处理
2. 模型选择与训练
3. 模型验证与参数调优

scikit-learn的基本功能主要被分为六个部分:

分类，回归，聚类，数据降维，模型选择，数据预处理

# 机器学习算法分类

机器学习的模型，

输入 --> 模型（特征向量）--> 输出


# 输出空间Y

  * 二类: 是非问题，Y= {true, false}
  * 多类: Y = { 1,2,3,...K } 
  * 结构学习: Y = structures (很多类别) 
  * 回归: Y=R(实数范围),即无限可能

分类问题
聚类问题
回归问题

二类分类应用非常广泛，比如判断是否为垃圾邮件、广告投资是否能盈利、学习系统上在下一题答题是否正确。
二类分类在机器学习中地位非常重要，是其他算法的基础。

多类别分类的应用，比如根据一张图片，得出图片中是苹果、橘子还是草莓等；
还有像Google邮箱，将邮件自动分成垃圾邮件、重要邮件、社交邮件、促销邮件等。
多类别分类在视觉或听觉的辨识中应用很广泛。

回归分析在股票价格预测和天气气温的预测上被广泛应用。

结构学习（Structured Learning）在自然语言处理中，自动的词性标注是很典型的结构学习的例子。
比如给定机器一个句子，由于词语在不同的句子当中可能会有不同的词性，i
所以该方法是用来对句子的结构特性的理解。这种学习方法可以被看做是多类别分类，
但与多类别分类不同的是，其目标的结构种类可能规模很大，其类别是隐藏在句子的背后的。
这种结构学习的例子还有例如说，生物中蛋白质3D立体结构，自然语言处理方面。

结构学习在有些地方被描述成标注（tagging）问题，标注问题的输入是一个观测序列，
输出是一个标记序列或状态序列。标注问题的目标在于学习一个模型，使它能够对观测序列给出标记序列作为预测。

# 特征向量

  * 监督学习（supervised learning）
  * 无监督学习（unsupervised learning）
    - 聚类（clustering）
      {x[n]} => cluster(x) 这里数据的类别是不知道的，根据某种规则得到不同的分类,
      可以近似看做无监督的多类别分类。
      例如：将文章按主题分类，或划分客户类型
    - 密度估计（density estimation），
      {x[n]} => density(x)
      这里的density(x) 可以是一个概率密度函数或者概率函数,
      可以近似看做无监督的有界回归问题。
      例如：根据位置的交通情况报告，预测事故危险多发的区域。
    - 异常检测（outlier detection）
      {x[n]} => unusual(x) ,可以看做近似的无监督二类分类问题。
      例如：根据网络的日志的情况，检测是否有异常入侵行为，
      这是一个极端的“是非题”，可以用非监督的方法来得出。
  * 半监督学习（Semi-supervised learning）
    监督学习与无监督学习相结合的一种学习方法。
    主要考虑如何利用少量的标注样本和大量的未标注样本进行训练和分类的问题。
    半监督学习是利用未标记的大量数据提升机器学习算法的表现效果。
    半监督学习的主要算法有五类：

    - 基于概率的算法；
    - 在现有监督算法基础上作修改的方法；直
    - 接依赖于聚类假设的方法；
    - 基于多试图的方法；
    基于图的方法。

    半监督学习的例子，比如Facebook上有关人脸照片的识别，可能只有一小部分人脸是被标记的，大部分是没有被标记的。

  * 增强学习（Reinforce learning）
    强化学习是一种以环境反馈作为输入的、特殊的、适应环境的机器学习方法。
    所谓强化学习是指从环境状态到行为映射的学习，以使系统行为从环境中获得的累积奖赏值最大。
    该方法不同与监督学习技术那样通过正例、反例来告知采取何种行为，
    而是通过试错（trial-and-error）的方法来发现最优行为策略。

    这里的输出并不一定是你真正想要得到的输出，而是用过奖励或者惩罚的方式来告诉这个系统做的好还是不好。
    比如一个线上广告系统，可以看做是顾客在训练这个广告系统。
    这个系统给顾客投放一个广告，即可能的输出，而顾客有没有点或者有没有因为这个广告赚钱，
    这评定了这个广告投放的好坏。这就让该广告系统学习到怎么样去放更适合的广告。

# 输入空间

  * 具体特征（concrete features）
    输入X的每一维特征都被人类进行的整理和分析，
    这种分析常常是与专业领域关联的
  * 原始特征（raw features）
    需要人或者机器进行转化，将原始特征转化成为具体的特征，
    在机器视觉和声音信号的辨识都是属于该类
  * 抽象特征（abstract features）


# 机器学习的训练方式



+ 批量学习（batch learning）
  一次性批量输入给学习算法，可以被形象的称为填鸭式学习。
+ 线上学习（online learning）
  按照顺序，循序的学习，不断的去修正模型，进行优化。
+ 主动学习（active learning）
  可以被看做是机器有问问题的能力，
  指定输入x[n]，询问其输出y[n].
  当label的获取成本非常昂贵时，会利用此法



# 算法分类

+ 有监督分类
  * 决策树
  * 信息增益
  * 分类回归树
  * 朴素贝叶斯
线性判别分析

Fishre判别，特征向量求解
K最邻近

相似度度量：欧氏距离、街区距离、编辑距离、向量夹角、Pearson相关系数
逻辑斯谛回归（二值分类）
参数估计（极大似然估计）、S型函数
径向基函数网络

非参数估计、正则化理论、S型函数
对偶传播网络

无导师的竞争学习、有导师的Widrow-Hoff学习
学习向量量化网络

一个输出层细胞跟几个竞争层细胞相连
误差反向传播网络

S型函数、梯度下降法
支持向量机（二值分类）

二次规化，Lagrange乘数法，对偶问题，最优化，序列最小优化，核技巧
单层感知器

只具有线性可分的能力
双隐藏层感知器

足以解决任何复杂的分类问题
+ 无监督分类
KMeans

质心
CHAMELONE

图划分，相对互连度，相对紧密度
BIRCH

B树，CF三元组
DBScan

核心点，密度可达
EM算法(高斯混合模型)

参数估计（极大似然估计）
谱聚类

图划分，奇异值求解 。全局收敛
自组织映射网络
无导师的竞争学习
回归分析

一般线性回归

参数估计，最小二乘法，一般不用于分类而用于预测
逻辑斯谛回归（二值分类）

参数估计（极大似然估计），S型函数
关联规则挖掘

FP-Tree

频繁1项集，FP-Tree，条件模式基，后缀模式
降维

主成分分析

协方差矩阵，奇异值分解
推荐

协同过滤
稀疏向量的相似度度量
